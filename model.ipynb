{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tff': conda)"
  },
  "interpreter": {
   "hash": "60b9f3cf9044eaf2109bd345a700078d38e5b2ad85556979c42d4867954610a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import backend\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import models, datasets, utils\r\n",
    "import os\r\n",
    "import numpy as np \r\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "\r\n",
    "def CNNmodel(input_shape,filters=64, kernel=(3,3),size=9,dropout=0.5,**kwargs):\r\n",
    "    _inputs = layers.Input(shape=input_shape)  # 48， 48， 1\r\n",
    "    x=layers.Conv2D(32,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu)(_inputs)\r\n",
    "    x=layers.Conv2D(32, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.MaxPool2D(pool_size=[2,2],strides=2,padding=\"same\")(x)\r\n",
    "    x=layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu)(_inputs)\r\n",
    "    x=layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.MaxPool2D(pool_size=[2,2],strides=2,padding=\"same\")(x)\r\n",
    "    x=layers.Dropout(0.25,name='dropout1')(x)\r\n",
    "    x=layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\")(x)\r\n",
    "    x=layers.Dropout(0.25,name='dropout3')(x)\r\n",
    "    x=layers.Conv2D(128, kernel_size=[1, 1], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.Conv2D(128, kernel_size=[1, 1], padding=\"same\", activation=tf.nn.relu)(x)\r\n",
    "    x=layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\")(x)\r\n",
    "    x=layers.Dropout(0.25,name='dropout4')(x)\r\n",
    "   \r\n",
    "    \r\n",
    "    x = layers.Flatten(name='flatten')(x)\r\n",
    "    x = layers.Dropout(dropout, name='dropout')(x)  \r\n",
    "\r\n",
    "    x=layers.Dense(128,activation=tf.nn.relu)(x)\r\n",
    "    x = layers.Dense(7, activation='softmax', name='FC')(x)\r\n",
    "    return keras.Model(inputs=_inputs,outputs=x)\r\n",
    "def preprocess_input(inputs, std=255. ,mean=0., expand_dims=None):\r\n",
    "    inputs = tf.cast(inputs,tf.float32)\r\n",
    "    inputs = (inputs - mean) / std\r\n",
    "    # print(inputs.shape)\r\n",
    "    if expand_dims is not None:\r\n",
    "        np.expand_dims(inputs,expand_dims)\r\n",
    "    # print(inputs.shape)\r\n",
    "    return inputs\r\n",
    "def img_aug_fun(elem):\r\n",
    "    elem = tf.image.random_flip_left_right(elem)#左右翻转\r\n",
    "    elem = tf.image.random_brightness(elem, max_delta=0.5)#调亮度\r\n",
    "    elem = tf.image.random_contrast(elem, lower=0.5, upper=1.5)#调对比度\r\n",
    "    elem = preprocess_input(elem)\r\n",
    "    return elem\r\n",
    "\r\n",
    "\r\n",
    "train=tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    r\"C:\\Users\\noname\\Desktop\\fer2013\\Training\", labels='inferred',label_mode='int',\r\n",
    "    class_names=None, color_mode='grayscale', batch_size=32, image_size=(48,48), shuffle=True,interpolation='bilinear'\r\n",
    ")\r\n",
    "#test=train=tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "  #  r\"C:\\Users\\noname\\Desktop\\fer2013\\PublicTest\", labels='inferred',label_mode='int',\r\n",
    "  #  class_names=None, color_mode='grayscale', batch_size=32, image_size=(48,48), shuffle=True,interpolation='bilinear'\r\n",
    "#)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 28709 files belonging to 7 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\n",
    "normalized_ds = train.map(lambda x, y: (normalization_layer(x), y))\r\n",
    "normalized_ds = test.map(lambda x, y: (normalization_layer(x), y))\r\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\r\n",
    "first_image = image_batch[0]\r\n",
    "print(np.min(first_image), np.max(first_image))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "model = CNNmodel(input_shape=(48,48,1),filters=64, kernel=(3,3),size=9)\r\n",
    "model.compile(optimizer='SGD',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
    "\r\n",
    "history = model.fit(train,validation_data=test,shuffle=True, batch_size=64, verbose=1,epochs=80)\r\n",
    "model.save('my_model1.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.9967 - accuracy: 0.2430 - val_loss: 1.7625 - val_accuracy: 0.2672\n",
      "Epoch 2/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.7560 - accuracy: 0.2834 - val_loss: 1.7252 - val_accuracy: 0.3012\n",
      "Epoch 3/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.7212 - accuracy: 0.3051 - val_loss: 1.7422 - val_accuracy: 0.2825\n",
      "Epoch 4/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.6829 - accuracy: 0.3321 - val_loss: 1.6139 - val_accuracy: 0.3644\n",
      "Epoch 5/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.6314 - accuracy: 0.3572 - val_loss: 1.7030 - val_accuracy: 0.3160\n",
      "Epoch 6/80\n",
      "898/898 [==============================] - 17s 18ms/step - loss: 1.5903 - accuracy: 0.3767 - val_loss: 1.5188 - val_accuracy: 0.4124\n",
      "Epoch 7/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.5518 - accuracy: 0.3942 - val_loss: 1.6400 - val_accuracy: 0.3541\n",
      "Epoch 8/80\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 1.5170 - accuracy: 0.4099 - val_loss: 1.5411 - val_accuracy: 0.3943\n",
      "Epoch 9/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.4822 - accuracy: 0.4260 - val_loss: 1.4582 - val_accuracy: 0.4413\n",
      "Epoch 10/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.4545 - accuracy: 0.4366 - val_loss: 1.4176 - val_accuracy: 0.4508\n",
      "Epoch 11/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.4296 - accuracy: 0.4491 - val_loss: 1.4746 - val_accuracy: 0.4249\n",
      "Epoch 12/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.4088 - accuracy: 0.4578 - val_loss: 1.3466 - val_accuracy: 0.4787\n",
      "Epoch 13/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.3896 - accuracy: 0.4637 - val_loss: 1.4791 - val_accuracy: 0.4154\n",
      "Epoch 14/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.3688 - accuracy: 0.4741 - val_loss: 1.3696 - val_accuracy: 0.4675\n",
      "Epoch 15/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.3513 - accuracy: 0.4810 - val_loss: 1.5190 - val_accuracy: 0.4021\n",
      "Epoch 16/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.3405 - accuracy: 0.4836 - val_loss: 1.3449 - val_accuracy: 0.4990\n",
      "Epoch 17/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.3207 - accuracy: 0.4969 - val_loss: 1.2823 - val_accuracy: 0.5091\n",
      "Epoch 18/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.3072 - accuracy: 0.4968 - val_loss: 1.2593 - val_accuracy: 0.5238\n",
      "Epoch 19/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2917 - accuracy: 0.5063 - val_loss: 1.2520 - val_accuracy: 0.5224\n",
      "Epoch 20/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2813 - accuracy: 0.5096 - val_loss: 1.2289 - val_accuracy: 0.5244\n",
      "Epoch 21/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2722 - accuracy: 0.5146 - val_loss: 1.2178 - val_accuracy: 0.5283\n",
      "Epoch 22/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2607 - accuracy: 0.5187 - val_loss: 1.4809 - val_accuracy: 0.4269\n",
      "Epoch 23/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2529 - accuracy: 0.5218 - val_loss: 1.2125 - val_accuracy: 0.5369\n",
      "Epoch 24/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2432 - accuracy: 0.5242 - val_loss: 1.2299 - val_accuracy: 0.5311\n",
      "Epoch 25/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2349 - accuracy: 0.5284 - val_loss: 1.2196 - val_accuracy: 0.5366\n",
      "Epoch 26/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.2263 - accuracy: 0.5313 - val_loss: 1.2350 - val_accuracy: 0.5294\n",
      "Epoch 27/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2150 - accuracy: 0.5399 - val_loss: 1.2097 - val_accuracy: 0.5325\n",
      "Epoch 28/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.2106 - accuracy: 0.5385 - val_loss: 1.2200 - val_accuracy: 0.5316\n",
      "Epoch 29/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.2007 - accuracy: 0.5402 - val_loss: 1.2319 - val_accuracy: 0.5249\n",
      "Epoch 30/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1965 - accuracy: 0.5409 - val_loss: 1.1682 - val_accuracy: 0.5570\n",
      "Epoch 31/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1889 - accuracy: 0.5477 - val_loss: 1.1730 - val_accuracy: 0.5553\n",
      "Epoch 32/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1828 - accuracy: 0.5477 - val_loss: 1.1926 - val_accuracy: 0.5472\n",
      "Epoch 33/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1779 - accuracy: 0.5482 - val_loss: 1.1921 - val_accuracy: 0.5403\n",
      "Epoch 34/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1655 - accuracy: 0.5537 - val_loss: 1.1744 - val_accuracy: 0.5469\n",
      "Epoch 35/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1657 - accuracy: 0.5557 - val_loss: 1.2161 - val_accuracy: 0.5361\n",
      "Epoch 36/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1605 - accuracy: 0.5574 - val_loss: 1.1362 - val_accuracy: 0.5545\n",
      "Epoch 37/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1510 - accuracy: 0.5632 - val_loss: 1.1664 - val_accuracy: 0.5447\n",
      "Epoch 38/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1438 - accuracy: 0.5634 - val_loss: 1.1452 - val_accuracy: 0.5653\n",
      "Epoch 39/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1416 - accuracy: 0.5655 - val_loss: 1.1734 - val_accuracy: 0.5472\n",
      "Epoch 40/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1349 - accuracy: 0.5667 - val_loss: 1.1870 - val_accuracy: 0.5528\n",
      "Epoch 41/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1290 - accuracy: 0.5714 - val_loss: 1.1412 - val_accuracy: 0.5637\n",
      "Epoch 42/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1248 - accuracy: 0.5724 - val_loss: 1.1710 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.1194 - accuracy: 0.5761 - val_loss: 1.1869 - val_accuracy: 0.5419\n",
      "Epoch 44/80\n",
      "898/898 [==============================] - 17s 19ms/step - loss: 1.1132 - accuracy: 0.5746 - val_loss: 1.1480 - val_accuracy: 0.5626\n",
      "Epoch 45/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.1089 - accuracy: 0.5790 - val_loss: 1.1271 - val_accuracy: 0.5756\n",
      "Epoch 46/80\n",
      "898/898 [==============================] - 17s 19ms/step - loss: 1.1049 - accuracy: 0.5801 - val_loss: 1.1371 - val_accuracy: 0.5665\n",
      "Epoch 47/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.1043 - accuracy: 0.5786 - val_loss: 1.1059 - val_accuracy: 0.5815\n",
      "Epoch 48/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0897 - accuracy: 0.5822 - val_loss: 1.2088 - val_accuracy: 0.5341\n",
      "Epoch 49/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0904 - accuracy: 0.5846 - val_loss: 1.1537 - val_accuracy: 0.5600\n",
      "Epoch 50/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0887 - accuracy: 0.5871 - val_loss: 1.2742 - val_accuracy: 0.5171\n",
      "Epoch 51/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0841 - accuracy: 0.5881 - val_loss: 1.1127 - val_accuracy: 0.5743\n",
      "Epoch 52/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0814 - accuracy: 0.5890 - val_loss: 1.1145 - val_accuracy: 0.5706\n",
      "Epoch 53/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0744 - accuracy: 0.5917 - val_loss: 1.1620 - val_accuracy: 0.5528\n",
      "Epoch 54/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0755 - accuracy: 0.5931 - val_loss: 1.1325 - val_accuracy: 0.5695\n",
      "Epoch 55/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.0656 - accuracy: 0.5954 - val_loss: 1.1209 - val_accuracy: 0.5773\n",
      "Epoch 56/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0673 - accuracy: 0.5951 - val_loss: 1.1362 - val_accuracy: 0.5695\n",
      "Epoch 57/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0616 - accuracy: 0.5963 - val_loss: 1.1300 - val_accuracy: 0.5701\n",
      "Epoch 58/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0564 - accuracy: 0.5988 - val_loss: 1.1139 - val_accuracy: 0.5782\n",
      "Epoch 59/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0533 - accuracy: 0.5998 - val_loss: 1.1269 - val_accuracy: 0.5676\n",
      "Epoch 60/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0456 - accuracy: 0.6023 - val_loss: 1.1073 - val_accuracy: 0.5756\n",
      "Epoch 61/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0475 - accuracy: 0.6018 - val_loss: 1.1175 - val_accuracy: 0.5748\n",
      "Epoch 62/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 1.0403 - accuracy: 0.6061 - val_loss: 1.1103 - val_accuracy: 0.5782\n",
      "Epoch 63/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.0359 - accuracy: 0.6085 - val_loss: 1.1513 - val_accuracy: 0.5659\n",
      "Epoch 64/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.0365 - accuracy: 0.6072 - val_loss: 1.1074 - val_accuracy: 0.5821\n",
      "Epoch 65/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.0285 - accuracy: 0.6097 - val_loss: 1.2000 - val_accuracy: 0.5511\n",
      "Epoch 66/80\n",
      "898/898 [==============================] - 15s 16ms/step - loss: 1.0302 - accuracy: 0.6089 - val_loss: 1.1020 - val_accuracy: 0.5798\n",
      "Epoch 67/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0262 - accuracy: 0.6103 - val_loss: 1.1307 - val_accuracy: 0.5687\n",
      "Epoch 68/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0209 - accuracy: 0.6121 - val_loss: 1.1155 - val_accuracy: 0.5751\n",
      "Epoch 69/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0197 - accuracy: 0.6154 - val_loss: 1.1157 - val_accuracy: 0.5918\n",
      "Epoch 70/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0165 - accuracy: 0.6142 - val_loss: 1.1186 - val_accuracy: 0.5748\n",
      "Epoch 71/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0103 - accuracy: 0.6181 - val_loss: 1.0982 - val_accuracy: 0.5921\n",
      "Epoch 72/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0070 - accuracy: 0.6165 - val_loss: 1.1152 - val_accuracy: 0.5784\n",
      "Epoch 73/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.0033 - accuracy: 0.6212 - val_loss: 1.1655 - val_accuracy: 0.5589\n",
      "Epoch 74/80\n",
      "898/898 [==============================] - 16s 17ms/step - loss: 1.0045 - accuracy: 0.6222 - val_loss: 1.0943 - val_accuracy: 0.5901\n",
      "Epoch 75/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.9967 - accuracy: 0.6205 - val_loss: 1.1141 - val_accuracy: 0.5815\n",
      "Epoch 76/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 0.9989 - accuracy: 0.6170 - val_loss: 1.1794 - val_accuracy: 0.5531\n",
      "Epoch 77/80\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 0.9950 - accuracy: 0.6230 - val_loss: 1.2641 - val_accuracy: 0.5252\n",
      "Epoch 78/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.9899 - accuracy: 0.6237 - val_loss: 1.1301 - val_accuracy: 0.5715\n",
      "Epoch 79/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.9859 - accuracy: 0.6261 - val_loss: 1.1729 - val_accuracy: 0.5497\n",
      "Epoch 80/80\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.9805 - accuracy: 0.6297 - val_loss: 1.1031 - val_accuracy: 0.5812\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# load model and test\r\n",
    "model_restore = models.load_model('.\\my_model1.h5')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: .\\my_model16.h5\\{saved_model.pbtxt|saved_model.pb}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-51be265c5592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load model and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_restore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\my_model16.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\anaconda\\envs\\tff\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tff\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    119\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tff\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: .\\my_model16.h5\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Evaluate on test data\")\r\n",
    "privtest=tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    r\"C:\\Users\\noname\\Desktop\\fer2013\\PrivateTest\", labels='inferred',label_mode='int',\r\n",
    "    class_names=None, color_mode='grayscale', batch_size=32, image_size=(48,48), interpolation='bilinear'\r\n",
    ")\r\n",
    "results = model.evaluate(privtest, batch_size=32)\r\n",
    "print(\"test loss, test acc:\", results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate on test data\n",
      "Found 3589 files belonging to 7 classes.\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 1.1044 - accuracy: 0.5907\n",
      "test loss, test acc: [1.1044200658798218, 0.5906937718391418]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "  _inputs = layers.Input(shape=input_shape)\r\n",
    "    x = layers.Conv2D(32,(3,3),padding='same',use_bias=False,strides=(1,1), name='conv_0')(_inputs)\r\n",
    "    x = layers.ReLU(6., name='conv_0_relu')(x)\r\n",
    "    x = layers.Conv2D(64,(3,3),padding='same',use_bias=False,strides=(1,1), name='conv_1')(x)\r\n",
    "    x = layers.ReLU(6., name='conv_1_relu')(x)\r\n",
    "    x = layers.Conv2D(64,(3,3),padding='same',use_bias=False,strides=(1,1), name='conv_2')(x)\r\n",
    "    x = layers.ReLU(6., name='conv_2_relu')(x)\r\n",
    "   \r\n",
    "    \r\n",
    "    x = layers.Conv2D(64,(3,3),padding='same',use_bias=False,strides=(1,1), name='conv_3')(x)\r\n",
    "    x = layers.ReLU(6., name='conv_3_relu')(x)\r\n",
    "    \r\n",
    "\r\n",
    "    x = layers.Conv2D(128,(3,3),padding='same',use_bias=False,strides=(1,1), name='conv_4')(x)\r\n",
    "    x = layers.ReLU(6., name='conv_4_relu')(x)\r\n"
   ],
   "metadata": {}
  }
 ]
}